#!/usr/bin/env bash
# Never ended up using this (because grouping by files is actually
# sort of useful, as it means it all came from the same machine)
# I basically only run this with:
# merge-csv-history 'my.ttt' 'ttt'

set -eu

declare SOURCE_DIR=

inputs() {
	find "${SOURCE_DIR?No source dir set}" -type f '(' -name '*merged*.csv' -o -mtime +7 ')' "$@"
}

run_merge() {
	inputs -exec csvstack -d',' -q'"' -u 0 {} + >"$1"
}

main() {
	local modulename source_name move_to write_to tempdir
	modulename="${1?Name of module, e.g. my.ttt}"
	source_name="${2?Source in backup_dir, e.g. ttt}"
	hpi doctor -S "$modulename"
	hash csvstack || {
		printf 'No csvstack binary found\n' >&2
		return 1
	}
	# source/temp/backup directories
	tempdir="$(mktemp -d)"
	SOURCE_DIR="$(backup_to "$source_name")"
	move_to="${HOME}/.cache/${source_name}_removed"
	# https://github.com/seanbreckenridge/core/blob/main/shellscripts/epoch
	write_to="${tempdir}/merged-$(epoch).csv"

	# backup to cache
	rsync -Pavh "$SOURCE_DIR"/ "$move_to"

	# run merge
	run_merge "$write_to"

	# remove files
	inputs -delete -print

	# move result from tmp to data dir
	mv -v "${write_to}" "${SOURCE_DIR}"

	# preview/parse to make sure this works
	dust "${SOURCE_DIR}"
	hpi doctor -S "$modulename"

	# removed merged backup files
	rm -i "${move_to}"/merged-*.csv
}

main "$@"
